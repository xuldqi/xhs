/**
 * AI Service - ç»Ÿä¸€çš„ AI API è°ƒç”¨æœåŠ¡
 * Supports OpenAI and Gemini
 */

export interface AIServiceConfig {
    apiKey: string;
    baseURL?: string;
    model?: string;
    provider?: 'openai' | 'gemini';
}

export interface AICompletionOptions {
    temperature?: number;
    maxTokens?: number;
    responseFormat?: 'text' | 'json';
}

export class AIService {
    private config: Required<AIServiceConfig>;
    private cache: Map<string, { data: string; timestamp: number }>;
    private readonly CACHE_TTL = 3600000; // 1å°æ—¶ç¼“å­˜

    constructor(config: AIServiceConfig) {
        this.config = {
            apiKey: config.apiKey,
            baseURL: config.baseURL || 'https://api.openai.com/v1',
            model: config.model || 'gpt-4o-mini',
            provider: config.provider || 'openai',
        };
        this.cache = new Map();
    }

    /**
     * ç”Ÿæˆæ–‡æœ¬è¡¥å…¨
     */
    async generateCompletion(
        prompt: string,
        options: AICompletionOptions = {}
    ): Promise<string> {
        const cacheKey = this.getCacheKey(prompt, options);

        // æ£€æŸ¥ç¼“å­˜
        const cached = this.getFromCache(cacheKey);
        if (cached) {
            console.log('ğŸ¯ Cache hit for prompt');
            return cached;
        }

        try {
            const response = await this.callAPI(prompt, options);

            // å­˜å…¥ç¼“å­˜
            this.cache.set(cacheKey, {
                data: response,
                timestamp: Date.now(),
            });

            return response;
        } catch (error) {
            console.error('AI Service Error:', error);
            throw new Error(`AI ç”Ÿæˆå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
        }
    }

    /**
     * ç”Ÿæˆ JSON æ ¼å¼å“åº”
     */
    async generateJSON<T = any>(
        prompt: string,
        options: AICompletionOptions = {}
    ): Promise<T> {
        const response = await this.generateCompletion(prompt, {
            ...options,
            responseFormat: 'json',
        });

        try {
            // å°è¯•æå– JSONï¼ˆæœ‰æ—¶ AI ä¼šè¿”å›é¢å¤–è¯´æ˜ï¼‰
            const jsonMatch = response.match(/\[[\s\S]*\]/);
            if (jsonMatch) {
                return JSON.parse(jsonMatch[0]);
            }
            return JSON.parse(response);
        } catch (error) {
            console.error('JSON Parse Error:', error);
            console.error('Raw response:', response);
            throw new Error('AI è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼');
        }
    }

    /**
     * è°ƒç”¨ OpenAI API
     */
    private async callOpenAI(
        prompt: string,
        options: AICompletionOptions
    ): Promise<string> {
        const response = await fetch(`${this.config.baseURL}/chat/completions`, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.config.apiKey}`,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                model: this.config.model,
                messages: [
                    {
                        role: 'user',
                        content: prompt,
                    },
                ],
                temperature: options.temperature ?? 0.9,
                max_tokens: options.maxTokens ?? 2000,
                ...(options.responseFormat === 'json' && {
                    response_format: { type: 'json_object' },
                }),
            }),
        });

        if (!response.ok) {
            const error = await response.json().catch(() => ({}));
            throw new Error(
                `OpenAI API é”™è¯¯ (${response.status}): ${error.error?.message || response.statusText}`
            );
        }

        const data = await response.json();
        return data.choices[0]?.message?.content || '';
    }

    /**
     * è°ƒç”¨ Gemini API
     */
    private async callGemini(
        prompt: string,
        options: AICompletionOptions
    ): Promise<string> {
        const endpoint = `${this.config.baseURL}/v1beta/models/${this.config.model}:generateContent`;

        const response = await fetch(`${endpoint}?key=${this.config.apiKey}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                contents: [
                    {
                        parts: [{ text: prompt }],
                    },
                ],
                generationConfig: {
                    temperature: options.temperature ?? 0.9,
                    maxOutputTokens: options.maxTokens ?? 2000,
                    ...(options.responseFormat === 'json' && {
                        responseMimeType: 'application/json',
                    }),
                },
            }),
        });

        if (!response.ok) {
            const error = await response.json().catch(() => ({}));
            throw new Error(
                `Gemini API é”™è¯¯ (${response.status}): ${error.error?.message || response.statusText}`
            );
        }

        const data = await response.json();
        return data.candidates[0]?.content?.parts[0]?.text || '';
    }

    /**
     * ç»Ÿä¸€ API è°ƒç”¨å…¥å£
     */
    private async callAPI(
        prompt: string,
        options: AICompletionOptions
    ): Promise<string> {
        if (this.config.provider === 'gemini') {
            return this.callGemini(prompt, options);
        }
        return this.callOpenAI(prompt, options);
    }

    /**
     * è·å–ç¼“å­˜é”®
     */
    private getCacheKey(prompt: string, options: AICompletionOptions): string {
        return `${prompt}_${JSON.stringify(options)}`;
    }

    /**
     * ä»ç¼“å­˜è·å–
     */
    private getFromCache(key: string): string | null {
        const cached = this.cache.get(key);
        if (!cached) return null;

        // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if (Date.now() - cached.timestamp > this.CACHE_TTL) {
            this.cache.delete(key);
            return null;
        }

        return cached.data;
    }

    /**
     * æ¸…é™¤ç¼“å­˜
     */
    clearCache(): void {
        this.cache.clear();
    }

    /**
     * æ¸…é™¤è¿‡æœŸç¼“å­˜
     */
    clearExpiredCache(): void {
        const now = Date.now();
        for (const [key, value] of this.cache.entries()) {
            if (now - value.timestamp > this.CACHE_TTL) {
                this.cache.delete(key);
            }
        }
    }
}

/**
 * åˆ›å»º AI Service å®ä¾‹çš„å·¥å‚å‡½æ•°
 */
export function createAIService(config: AIServiceConfig): AIService {
    return new AIService(config);
}

/**
 * é»˜è®¤é…ç½® - OpenAI
 */
export function createOpenAIService(apiKey: string): AIService {
    return new AIService({
        apiKey,
        provider: 'openai',
        model: 'gpt-4o-mini',
        baseURL: 'https://api.openai.com/v1',
    });
}

/**
 * é»˜è®¤é…ç½® - Gemini
 */
export function createGeminiService(apiKey: string): AIService {
    return new AIService({
        apiKey,
        provider: 'gemini',
        model: 'gemini-1.5-flash',
        baseURL: 'https://generativelanguage.googleapis.com',
    });
}

// ============ åç«¯ API å®¢æˆ·ç«¯ï¼ˆä¾› AnalysisViewã€guideGenerator ä½¿ç”¨ï¼‰ ============
const API_BASE = import.meta.env.VITE_BACKEND_URL || ''

async function apiPost(path: string, body: any) {
    const res = await fetch(`${API_BASE}/api/ai${path}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
    })
    return res.json()
}

async function apiGet(path: string) {
    const res = await fetch(`${API_BASE}/api/ai${path}`)
    return res.json()
}

export const aiService = {
    isConfigured(): boolean {
        return !!API_BASE
    },
    async isConfiguredAsync(): Promise<boolean> {
        try {
            const data = await apiGet('/health')
            return data?.configured === true
        } catch {
            return false
        }
    },
    async analyzeImage(params: { image: string; prompt: string }) {
        return apiPost('/analyze', { image: params.image, prompt: params.prompt })
    },
    async generateContent(params: { accountData: any; sectionId: number; template: string; context: string }) {
        const { accountData, sectionId, template, context } = params
        const systemPrompt = `ä½ æ˜¯å°çº¢ä¹¦è¿è¥ä¸“å®¶ã€‚æ ¹æ®è´¦å·æ•°æ®ç”Ÿæˆæ¶¨ç²‰æŒ‡å—ç« èŠ‚ã€‚
è´¦å·ï¼š${accountData?.username || 'æœªçŸ¥'}ï¼Œç²‰ä¸ï¼š${accountData?.followers ?? 0}ï¼Œç¬”è®°æ•°ï¼š${accountData?.notes ?? 0}ï¼Œç±»åˆ«ï¼š${accountData?.category || 'æœªåˆ†ç±»'}
ä¸¥æ ¼éµå®ˆæ ¼å¼è§„èŒƒï¼Œä½¿ç”¨ emoji + åˆ—è¡¨æ ¼å¼ï¼Œä¸è¦ç”¨ Markdown æ ‡é¢˜æˆ–åŠ ç²—ã€‚`
        const userPrompt = `ç« èŠ‚ ${sectionId}ï¼š\n${template}\n\nä¸Šä¸‹æ–‡ï¼š${context || 'æ— '}`
        return apiPost('/generate', { systemPrompt, userPrompt })
    },
    async generateKeywords(topic: string, subNiche?: string) {
        const systemPrompt = `ä½ æ˜¯å°çº¢ä¹¦ SEO ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„å†…å®¹é¢†åŸŸï¼Œè¾“å‡ºé€‚åˆå°çº¢ä¹¦æœç´¢ä¼˜åŒ–çš„å…³é”®è¯ã€‚
å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{
  "coreKeywords": ["æ ¸å¿ƒè¯1", "æ ¸å¿ƒè¯2", "æ ¸å¿ƒè¯3", "æ ¸å¿ƒè¯4", "æ ¸å¿ƒè¯5"],
  "longTailKeywords": ["é•¿å°¾è¯1", "é•¿å°¾è¯2", "é•¿å°¾è¯3", "é•¿å°¾è¯4", "é•¿å°¾è¯5"],
  "relatedKeywords": ["ç›¸å…³è¯1", "ç›¸å…³è¯2", "ç›¸å…³è¯3"],
  "usageTips": "50-100å­—çš„ä½¿ç”¨å»ºè®®ï¼Œè¯´æ˜å¦‚ä½•åœ¨æ ‡é¢˜ã€æ­£æ–‡ã€è¯é¢˜æ ‡ç­¾ä¸­å¸ƒå±€è¿™äº›å…³é”®è¯"
}
coreKeywords: ç”¨æˆ·æœ€å¯èƒ½æœç´¢çš„ä¸»å…³é”®è¯ï¼Œ3-5ä¸ªã€‚
longTailKeywords: æ›´å…·ä½“çš„é•¿å°¾è¯ï¼Œç«äº‰å°ã€è½¬åŒ–é«˜ï¼Œå¦‚ã€Œå¹³ä»·å­¦ç”Ÿå…šæŠ¤è‚¤æ¨èã€ã€‚
relatedKeywords: æ‹“å±•ç›¸å…³è¯ï¼Œå¯ç”¨äºè¯é¢˜æ ‡ç­¾ã€‚
usageTips: ç®€çŸ­å®ç”¨çš„å¸ƒå±€å»ºè®®ã€‚`
        const userPrompt = subNiche
            ? `é¢†åŸŸï¼š${topic}ï¼Œç»†åˆ†æ–¹å‘ï¼š${subNiche}\nè¯·è¾“å‡ºé€‚åˆè¯¥ç»†åˆ†é¢†åŸŸçš„å…³é”®è¯ JSONã€‚`
            : `é¢†åŸŸï¼š${topic}\nè¯·è¾“å‡ºé€‚åˆè¯¥é¢†åŸŸçš„å…³é”®è¯ JSONã€‚`
        return apiPost('/generate', { systemPrompt, userPrompt })
    },
    async generateTitles(params: { topic: string; keywords?: string; style: string; count: number }) {
        const styleNames: Record<string, string> = {
            catchy: 'å¸ç›å‹ï¼ˆå¤¸å¼ ã€æƒŠå¹ã€å¸å¼•ç‚¹å‡»ï¼‰',
            professional: 'ä¸“ä¸šå‹ï¼ˆæœ¯è¯­ã€æƒå¨æ„Ÿï¼‰',
            emotional: 'æƒ…æ„Ÿå‹ï¼ˆå…±é¸£ã€èµ°å¿ƒï¼‰',
            question: 'ç–‘é—®å‹ï¼ˆå¼•å‘å¥½å¥‡ï¼‰',
            numeric: 'æ•°å­—å‹ï¼ˆå…·ä½“æ•°å­—ã€å¯ä¿¡ï¼‰'
        }
        const styleDesc = styleNames[params.style] || 'å¸ç›å‹'
        const systemPrompt = `ä½ æ˜¯å°çº¢ä¹¦æ ‡é¢˜ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„å†…å®¹ä¸»é¢˜å’Œé£æ ¼ï¼Œç”ŸæˆæŒ‡å®šæ•°é‡çš„å°çº¢ä¹¦ç¬”è®°æ ‡é¢˜ã€‚
å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  { "text": "æ ‡é¢˜æ–‡æ¡ˆ1", "score": 85 },
  { "text": "æ ‡é¢˜æ–‡æ¡ˆ2", "score": 90 }
]
è¦æ±‚ï¼šæ¯ä¸ªæ ‡é¢˜ 15-25 å­—ï¼ŒåŒ…å« emojiï¼Œç¬¦åˆå°çº¢ä¹¦é£æ ¼ï¼›score ä¸º 70-95 çš„å¸å¼•åŠ›è¯„åˆ†ã€‚`
        const userPrompt = `ä¸»é¢˜ï¼š${params.topic}
${params.keywords ? `å…³é”®è¯ï¼ˆå¯èå…¥æ ‡é¢˜ï¼‰ï¼š${params.keywords}` : ''}
é£æ ¼ï¼š${styleDesc}
ç”Ÿæˆæ•°é‡ï¼š${params.count} ä¸ªæ ‡é¢˜ã€‚è¯·ç›´æ¥è¾“å‡º JSON æ•°ç»„ã€‚`
        return apiPost('/generate', { systemPrompt, userPrompt })
    },
    async analyzeTopics(domain: string, timeRange?: string) {
        const systemPrompt = `ä½ æ˜¯å°çº¢ä¹¦è¿è¥ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„å†…å®¹é¢†åŸŸï¼Œè¾“å‡ºè¿‘æœŸçƒ­é—¨è¯é¢˜è¶‹åŠ¿åˆ†æã€‚
å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{
  "hotTopics": [
    { "topic": "è¯é¢˜åç§°", "trend": "ä¸Šå‡/ç¨³å®š", "reason": "20å­—å†…è¯´æ˜" },
    ...
  ],
  "contentSuggestions": ["å†…å®¹å»ºè®®1", "å†…å®¹å»ºè®®2", "å†…å®¹å»ºè®®3"],
  "avoidTopics": ["é¿å…çš„è¯é¢˜1", "é¿å…çš„è¯é¢˜2"],
  "summary": "50-80å­—æ€»ç»“ï¼Œç»™ç”¨æˆ·æ˜ç¡®çš„æ–¹å‘å»ºè®®"
}
hotTopics: 3-5ä¸ªè¿‘æœŸçƒ­é—¨è¯é¢˜ï¼Œtrendä¸ºä¸Šå‡/ç¨³å®šã€‚
contentSuggestions: 3-4ä¸ªå¯æ‰§è¡Œçš„å†…å®¹é€‰é¢˜å»ºè®®ã€‚
avoidTopics: 1-2ä¸ªåº”é¿å…çš„è¯é¢˜æˆ–æ–¹å‘ã€‚
summary: ç®€æ˜æ‰¼è¦çš„æ€»ç»“å»ºè®®ã€‚`
        const userPrompt = timeRange
            ? `é¢†åŸŸï¼š${domain}ï¼Œå…³æ³¨æ—¶æ®µï¼š${timeRange}\nè¯·è¾“å‡ºè¯é¢˜è¶‹åŠ¿åˆ†æ JSONã€‚`
            : `é¢†åŸŸï¼š${domain}\nè¯·è¾“å‡ºè¿‘æœŸçƒ­é—¨è¯é¢˜è¶‹åŠ¿åˆ†æ JSONã€‚`
        return apiPost('/generate', { systemPrompt, userPrompt })
    },
    async analyzeCompetitor(competitorDesc: string, yourPositioning?: string) {
        const systemPrompt = `ä½ æ˜¯å°çº¢ä¹¦è¿è¥ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„ç«å“è´¦å·æè¿°ï¼Œè¾“å‡ºç«å“åˆ†ææŠ¥å‘Šã€‚
å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{
  "strengths": ["ä¼˜åŠ¿1", "ä¼˜åŠ¿2", "ä¼˜åŠ¿3"],
  "weaknesses": ["åŠ£åŠ¿1", "åŠ£åŠ¿2"],
  "contentStrategy": "50-80å­—æè¿°å…¶å†…å®¹ç­–ç•¥",
  "differentiation": ["å·®å¼‚åŒ–æœºä¼š1", "å·®å¼‚åŒ–æœºä¼š2", "å·®å¼‚åŒ–æœºä¼š3"],
  "actionItems": ["å»ºè®®è¡ŒåŠ¨1", "å»ºè®®è¡ŒåŠ¨2", "å»ºè®®è¡ŒåŠ¨3"],
  "summary": "50-80å­—æ€»ç»“ï¼Œç»™ç”¨æˆ·æ˜ç¡®çš„ç«å“å­¦ä¹ ä¸å·®å¼‚åŒ–å»ºè®®"
}
strengths: ç«å“çš„3-4ä¸ªä¼˜åŠ¿ã€‚
weaknesses: ç«å“çš„2-3ä¸ªå¯å€Ÿé‰´çš„çŸ­æ¿ã€‚
contentStrategy: å…¶å†…å®¹ç­–ç•¥ç®€è¿°ã€‚
differentiation: ç”¨æˆ·å¯é‡‡å–çš„3ä¸ªå·®å¼‚åŒ–æ–¹å‘ã€‚
actionItems: 3-4ä¸ªå¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®ã€‚
summary: ç®€æ˜æ‰¼è¦çš„æ€»ç»“ã€‚`
        const userPrompt = yourPositioning
            ? `ç«å“æè¿°ï¼š${competitorDesc}\næˆ‘çš„è´¦å·å®šä½ï¼š${yourPositioning}\nè¯·è¾“å‡ºç«å“åˆ†æ JSONã€‚`
            : `ç«å“æè¿°ï¼š${competitorDesc}\nè¯·è¾“å‡ºç«å“åˆ†æ JSONã€‚`
        return apiPost('/generate', { systemPrompt, userPrompt })
    },
}
