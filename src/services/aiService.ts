import type { 
  AIAnalysisRequest, 
  AIGenerationRequest, 
  AIResponse, 
  AccountData 
} from '@/types'
import { API_CONFIG, PERFORMANCE_CONFIG, ERROR_MESSAGES } from '@/types'

class AIService {
  private useProxy: boolean
  private proxyUrl: string
  private apiKey: string
  private baseUrl: string
  private provider: 'openai' | 'deepseek' | 'gemini'
  
  constructor() {
    // ä¼˜å…ˆä½¿ç”¨ä»£ç†æ¨¡å¼ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    this.useProxy = import.meta.env.VITE_USE_PROXY !== 'false'
    this.proxyUrl = import.meta.env.VITE_PROXY_URL || '/api/ai'
    
    // å¼€å‘æ¨¡å¼å¯ä»¥ç›´æ¥ä½¿ç”¨ API Key
    this.apiKey = import.meta.env.VITE_OPENAI_API_KEY || ''
    this.baseUrl = import.meta.env.VITE_API_BASE_URL || 'https://api.openai.com'
    
    // æ ¹æ® baseUrl åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæä¾›å•†
    if (this.baseUrl.includes('deepseek')) {
      this.provider = 'deepseek'
    } else if (this.baseUrl.includes('generativelanguage.googleapis.com')) {
      this.provider = 'gemini'
    } else {
      this.provider = 'openai'
    }
  }
  
  /**
   * åˆ†æå›¾ç‰‡ï¼Œæå–è´¦å·ä¿¡æ¯
   */
  async analyzeImage(request: AIAnalysisRequest): Promise<AIResponse<AccountData>> {
    return this.retryRequest(async () => {
      try {
        // ä½¿ç”¨ä»£ç†æ¨¡å¼
        if (this.useProxy) {
          const response = await fetch(`${this.proxyUrl}/analyze`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              prompt: request.prompt,
              image: request.image
            })
          })
          
          if (!response.ok) {
            const errorData = await response.json().catch(() => ({}))
            throw new Error(errorData.message || `ä»£ç†è¯·æ±‚å¤±è´¥: ${response.statusText}`)
          }
          
          const data = await response.json()
          const content = data.choices[0]?.message?.content
          
          if (!content) {
            throw new Error('AI è¿”å›å†…å®¹ä¸ºç©º')
          }
          
          const accountData = JSON.parse(content) as AccountData
          
          return {
            success: true,
            data: accountData,
            tokensUsed: data.usage?.total_tokens || 0
          }
        }
        
        // ç›´æ¥è°ƒç”¨æ¨¡å¼ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        if (this.provider === 'gemini') {
          return await this.analyzeImageGemini(request)
        }
        
        const response = await fetch(`${this.baseUrl}/v1/chat/completions`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify({
            model: this.getVisionModel(),
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'text',
                    text: request.prompt
                  },
                  {
                    type: 'image_url',
                    image_url: {
                      url: `data:image/jpeg;base64,${request.image}`
                    }
                  }
                ]
              }
            ],
            max_tokens: API_CONFIG.MAX_TOKENS,
            temperature: API_CONFIG.TEMPERATURE
          })
        })
        
        if (!response.ok) {
          throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.statusText}`)
        }
        
        const data = await response.json()
        const content = data.choices[0]?.message?.content
        
        if (!content) {
          throw new Error('AI è¿”å›å†…å®¹ä¸ºç©º')
        }
        
        // è§£æ JSON å“åº”
        const accountData = JSON.parse(content) as AccountData
        
        return {
          success: true,
          data: accountData,
          tokensUsed: data.usage?.total_tokens || 0
        }
      } catch (error) {
        return {
          success: false,
          data: {} as AccountData,
          error: error instanceof Error ? error.message : ERROR_MESSAGES.ANALYSIS_FAILED,
          tokensUsed: 0
        }
      }
    })
  }
  
  /**
   * ç”ŸæˆæŒ‡å—å†…å®¹
   */
  async generateContent(request: AIGenerationRequest): Promise<AIResponse<string>> {
    return this.retryRequest(async () => {
      try {
        console.log(`ğŸ¤– [ç« èŠ‚ ${request.sectionId}] å¼€å§‹ç”Ÿæˆ...`)
        console.log(`ğŸ“¡ ä½¿ç”¨æ¨¡å¼: ${this.useProxy ? 'ä»£ç†æ¨¡å¼' : 'ç›´è¿æ¨¡å¼'}`)
        
        const systemPrompt = 'ä½ æ˜¯ä¸€ä½å°çº¢ä¹¦è¿è¥ä¸“å®¶ï¼Œç²¾é€šå¹³å°ç®—æ³•å’Œç”¨æˆ·å¿ƒç†ã€‚'
        const userPrompt = this.buildPrompt(request)
        
        // ä½¿ç”¨ä»£ç†æ¨¡å¼
        if (this.useProxy) {
          const response = await fetch(`${this.proxyUrl}/generate`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              systemPrompt,
              userPrompt
            })
          })
          
          if (!response.ok) {
            const errorData = await response.json().catch(() => ({}))
            throw new Error(errorData.message || `ä»£ç†è¯·æ±‚å¤±è´¥: ${response.statusText}`)
          }
          
          const data = await response.json()
          const content = data.choices[0]?.message?.content
          
          if (!content) {
            throw new Error('AI è¿”å›å†…å®¹ä¸ºç©º')
          }
          
          console.log(`âœ… [ç« èŠ‚ ${request.sectionId}] ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: ${content.length}`)
          
          return {
            success: true,
            data: content,
            tokensUsed: data.usage?.total_tokens || 0
          }
        }
        
        // ç›´æ¥è°ƒç”¨æ¨¡å¼ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        console.log(`ğŸ”— API åœ°å€: ${this.baseUrl}`)
        
        if (this.provider === 'gemini') {
          return await this.generateContentGemini(request)
        }
        
        // æ„å»ºè¯·æ±‚ä½“ - DeepSeek å…¼å®¹æ ¼å¼
        const messages: any[] = []
        
        // DeepSeek æ”¯æŒ system role
        if (this.provider === 'deepseek') {
          messages.push({
            role: 'system',
            content: systemPrompt
          })
          messages.push({
            role: 'user',
            content: userPrompt
          })
        } else {
          messages.push({
            role: 'user',
            content: `${systemPrompt}\n\n${userPrompt}`
          })
        }
        
        const requestBody: any = {
          model: this.getTextModel(),
          messages: messages,
          temperature: API_CONFIG.TEMPERATURE,
          max_tokens: 2000
        }
        
        console.log(`ğŸ“¤ è¯·æ±‚ä½“:`, JSON.stringify(requestBody).substring(0, 200) + '...')
        
        const response = await fetch(`${this.baseUrl}/v1/chat/completions`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify(requestBody)
        })
        
        console.log(`ğŸ“¥ å“åº”çŠ¶æ€: ${response.status} ${response.statusText}`)
        
        if (!response.ok) {
          let errorText = ''
          let errorJson: any = null
          
          try {
            errorText = await response.text()
            errorJson = JSON.parse(errorText)
            console.error(`âŒ API é”™è¯¯å“åº” (JSON):`, errorJson)
          } catch {
            console.error(`âŒ API é”™è¯¯å“åº” (Text):`, errorText)
          }
          
          const errorMessage = errorJson?.error?.message || errorJson?.message || errorText || response.statusText
          throw new Error(`API è¯·æ±‚å¤±è´¥ (${response.status}): ${errorMessage}`)
        }
        
        const data = await response.json()
        const content = data.choices[0]?.message?.content
        
        if (!content) {
          console.error(`âŒ AI è¿”å›å†…å®¹ä¸ºç©º`, data)
          throw new Error('AI è¿”å›å†…å®¹ä¸ºç©º')
        }
        
        console.log(`âœ… [ç« èŠ‚ ${request.sectionId}] ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: ${content.length}`)
        
        return {
          success: true,
          data: content,
          tokensUsed: data.usage?.total_tokens || 0
        }
      } catch (error) {
        console.error(`âŒ [ç« èŠ‚ ${request.sectionId}] ç”Ÿæˆå¤±è´¥:`, error)
        return {
          success: false,
          data: '',
          error: error instanceof Error ? error.message : ERROR_MESSAGES.GENERATION_FAILED,
          tokensUsed: 0
        }
      }
    })
  }
  
  /**
   * æ„å»ºç”Ÿæˆæç¤ºè¯
   */
  private buildPrompt(request: AIGenerationRequest): string {
    const { accountData, template, context } = request
    
    let prompt = template
    
    // æ›¿æ¢æ¨¡æ¿å˜é‡
    prompt = prompt.replace(/\{username\}/g, accountData.username)
    prompt = prompt.replace(/\{followerCount\}/g, accountData.followerCount.toString())
    prompt = prompt.replace(/\{postCount\}/g, accountData.postCount.toString())
    prompt = prompt.replace(/\{contentCategory\}/g, accountData.contentCategory)
    
    if (context) {
      prompt += `\n\né¢å¤–ä¸Šä¸‹æ–‡ï¼š${context}`
    }
    
    return prompt
  }
  
  /**
   * é‡è¯•æœºåˆ¶
   */
  private async retryRequest<T>(
    fn: () => Promise<AIResponse<T>>,
    maxAttempts = PERFORMANCE_CONFIG.RETRY_MAX_ATTEMPTS
  ): Promise<AIResponse<T>> {
    let lastError: AIResponse<T> | null = null
    
    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
      const result = await fn()
      
      if (result.success) {
        return result
      }
      
      lastError = result
      
      // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
      if (attempt < maxAttempts) {
        await this.delay(PERFORMANCE_CONFIG.RETRY_DELAY * attempt)
      }
    }
    
    return lastError || {
      success: false,
      data: {} as T,
      error: ERROR_MESSAGES.AI_SERVICE_ERROR,
      tokensUsed: 0
    }
  }
  
  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }
  
  /**
   * Gemini å›¾åƒåˆ†æ
   */
  private async analyzeImageGemini(request: AIAnalysisRequest): Promise<AIResponse<AccountData>> {
    const response = await fetch(
      `${this.baseUrl}/v1beta/models/gemini-pro-vision:generateContent?key=${this.apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          contents: [{
            parts: [
              { text: request.prompt },
              {
                inline_data: {
                  mime_type: 'image/jpeg',
                  data: request.image
                }
              }
            ]
          }]
        })
      }
    )
    
    if (!response.ok) {
      throw new Error(`Gemini API è¯·æ±‚å¤±è´¥: ${response.statusText}`)
    }
    
    const data = await response.json()
    const content = data.candidates?.[0]?.content?.parts?.[0]?.text
    
    if (!content) {
      throw new Error('Gemini è¿”å›å†…å®¹ä¸ºç©º')
    }
    
    const accountData = JSON.parse(content) as AccountData
    
    return {
      success: true,
      data: accountData,
      tokensUsed: data.usageMetadata?.totalTokenCount || 0
    }
  }
  
  /**
   * Gemini å†…å®¹ç”Ÿæˆ
   */
  private async generateContentGemini(request: AIGenerationRequest): Promise<AIResponse<string>> {
    const prompt = 'ä½ æ˜¯ä¸€ä½å°çº¢ä¹¦è¿è¥ä¸“å®¶ï¼Œç²¾é€šå¹³å°ç®—æ³•å’Œç”¨æˆ·å¿ƒç†ã€‚\n\n' + this.buildPrompt(request)
    
    const response = await fetch(
      `${this.baseUrl}/v1beta/models/gemini-pro:generateContent?key=${this.apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          contents: [{
            parts: [{ text: prompt }]
          }],
          generationConfig: {
            temperature: API_CONFIG.TEMPERATURE,
            maxOutputTokens: API_CONFIG.MAX_TOKENS
          }
        })
      }
    )
    
    if (!response.ok) {
      throw new Error(`Gemini API è¯·æ±‚å¤±è´¥: ${response.statusText}`)
    }
    
    const data = await response.json()
    const content = data.candidates?.[0]?.content?.parts?.[0]?.text
    
    if (!content) {
      throw new Error('Gemini è¿”å›å†…å®¹ä¸ºç©º')
    }
    
    return {
      success: true,
      data: content,
      tokensUsed: data.usageMetadata?.totalTokenCount || 0
    }
  }
  
  /**
   * è·å–è§†è§‰æ¨¡å‹åç§°
   */
  private getVisionModel(): string {
    if (this.provider === 'deepseek') {
      return 'deepseek-chat'
    } else if (this.provider === 'gemini') {
      return 'gemini-pro-vision'
    }
    return API_CONFIG.OPENAI_MODEL
  }
  
  /**
   * è·å–æ–‡æœ¬æ¨¡å‹åç§°
   */
  private getTextModel(): string {
    if (this.provider === 'deepseek') {
      return 'deepseek-chat'
    } else if (this.provider === 'gemini') {
      return 'gemini-pro'
    }
    return API_CONFIG.OPENAI_TEXT_MODEL
  }
  
  /**
   * æ£€æŸ¥ API å¯†é’¥æ˜¯å¦é…ç½®
   */
  isConfigured(): boolean {
    return !!this.apiKey && this.apiKey !== ''
  }
  
  /**
   * è·å–å½“å‰ä½¿ç”¨çš„æä¾›å•†
   */
  getProvider(): string {
    return this.provider
  }
}

// å¯¼å‡ºå•ä¾‹
export const aiService = new AIService()
